{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import ast "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta secção, vamos juntar todos os produtos extraidos  de cada um dos sites seja em black friday ou não, vamos criar um dataset com todos os produtos e respectivas informações. Depois vamos fazer uma limpeza dos dados repetidos e por fim aplicar um modelo de agregação e categorização dos produtos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(\"data/*products_extracted_prices*.csv\") # with glob we can get all the files that match the pattern\n",
    "dataframes = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    if \"Black_Friday\" in file_path:\n",
    "        df['promocao'] = 'Black Friday'\n",
    "    else:\n",
    "        df['promocao'] = 'Sem Promocao'\n",
    "    \n",
    "    dataframes.append(df)\n",
    "\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"all_prices_extracted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo vou so fazer um teste para ter a certeza que o codigo acima funcionou como pretendido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Black Friday rows across all files: 839\n",
      "Total Black Friday rows on merged DataFrame: 839\n",
      "Total Not Black Friday rows across all files: 703\n",
      "Total Not Black Friday rows on merged DataFrame: 703\n"
     ]
    }
   ],
   "source": [
    "file_paths = glob.glob(\"data/*products_extracted_prices*.csv\") \n",
    "\n",
    "black_friday_counts = {}\n",
    "not_black_friday_counts = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    if \"Black_Friday\" in file_path:\n",
    "        df = pd.read_csv(file_path)\n",
    "        black_friday_counts[file_path] = df.shape[0]\n",
    "    else:\n",
    "        df = pd.read_csv(file_path)\n",
    "        not_black_friday_counts[file_path] = df.shape[0]\n",
    "        \n",
    "total_black_friday_rows = sum(black_friday_counts.values())\n",
    "print(f\"Total Black Friday rows across all files: {total_black_friday_rows}\")\n",
    "total_black_friday_rows_on_merged_df = merged_df[merged_df['promocao'] == 'Black Friday'].shape[0]\n",
    "print(f\"Total Black Friday rows on merged DataFrame: {total_black_friday_rows_on_merged_df}\")\n",
    "\n",
    "total_not_black_friday_rows = sum(not_black_friday_counts.values())\n",
    "print(f\"Total Not Black Friday rows across all files: {total_not_black_friday_rows}\")\n",
    "total_not_black_friday_rows_on_merged_df = merged_df[merged_df['promocao'] == 'Sem Promocao'].shape[0]\n",
    "print(f\"Total Not Black Friday rows on merged DataFrame: {total_not_black_friday_rows_on_merged_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(\"all_prices_extracted.csv\")\n",
    "merged_df = merged_df.drop(columns=['linkToArchive','linkToExtractedText','snippet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site              0\n",
       "date              0\n",
       "title            16\n",
       "extractedData    55\n",
       "promocao          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site             0\n",
       "date             0\n",
       "title            0\n",
       "extractedData    0\n",
       "promocao         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminate rows with missing values\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (1476, 5)\n",
      "Shape after: (967, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape before: {merged_df.shape}\")\n",
    "\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "print(f\"Shape after: {merged_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_extracted_data(extracted_str):\n",
    "    try:\n",
    "        extracted_list = ast.literal_eval(extracted_str) # é suado para converter as strings em listas\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []  \n",
    "\n",
    "    cleaned_prices = []\n",
    "    for price in extracted_list:\n",
    "        normalized_price = unicodedata.normalize(\"NFKD\", price)\n",
    "        cleaned_price = re.sub(r'[^\\d,]', '', normalized_price)\n",
    "        cleaned_prices.append(cleaned_price)\n",
    "    \n",
    "    return cleaned_prices\n",
    "\n",
    "merged_df['extractedData'] = merged_df['extractedData'].apply(clean_extracted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"all_prices_extracted_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
